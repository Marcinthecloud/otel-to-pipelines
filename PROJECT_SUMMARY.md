# Project Summary: OTLP to Cloudflare Pipelines

## ğŸ“¦ What This Project Does

This Cloudflare Worker receives OpenTelemetry Protocol (OTLP) logs from Cloudflare Workers and other sources, then forwards them to Cloudflare Pipelines for long-term storage and SQL-based analysis.

## ğŸ¯ Key Features

1. **Native Integration**: Works with Cloudflare's built-in OTLP export feature
2. **Gzip Handling**: Auto-decompresses gzip-compressed OTLP data
3. **Dual Interface**: Supports both RPC (native) and HTTP POST endpoints
4. **Full OTLP Support**: Preserves all metadata, trace IDs, and attributes
5. **Production Ready**: Clean, documented, tested code

## ğŸ—ï¸ Architecture

```
Source Worker â†’ OTLP (gzip+JSON) â†’ This Worker â†’ Pipelines Stream â†’ SQL Analysis
```

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts          - Main worker (RPC + HTTP handlers)
â”‚   â”œâ”€â”€ types.ts          - TypeScript types
â”‚   â””â”€â”€ transformer.ts    - OTLP â†’ Pipelines transformation
â”œâ”€â”€ pipelines-schema.json - Stream schema (nanoseconds)
â”œâ”€â”€ sink-schema.json      - Sink schema (microseconds)
â”œâ”€â”€ transform-to-sink.sql - NS â†’ ÂµS conversion SQL
â”œâ”€â”€ example-request.json  - Test data
â”œâ”€â”€ wrangler.toml.example - Config template
â”œâ”€â”€ README.md             - Full documentation
â”œâ”€â”€ CONTRIBUTING.md       - Contribution guidelines
â”œâ”€â”€ TROUBLESHOOTING.md    - Debug guide
â”œâ”€â”€ LICENSE               - MIT license
â””â”€â”€ .github/              - Issue/PR templates
```

## ğŸš€ Quick Start for Users

```bash
# 1. Clone and install
git clone https://github.com/yourusername/otlp-to-pipelines.git
cd otlp-to-pipelines
npm install

# 2. Create pipeline
wrangler pipelines create otlp-logs-stream
wrangler pipelines update otlp-logs-stream --schema pipelines-schema.json

# 3. Configure
cp wrangler.toml.example wrangler.toml
# Edit wrangler.toml with your pipeline ID

# 4. Deploy
npm run deploy

# 5. Configure OTLP source in Cloudflare dashboard
```

## ğŸ› ï¸ Development Workflow

```bash
# Local development
npm run dev

# Test
curl -X POST http://localhost:8787/v1/logs \
  -H "Content-Type: application/json" \
  -d @example-request.json

# Monitor logs
npm run tail

# Deploy
npm run deploy
```

## ğŸ“Š Data Flow

### Input (OTLP JSON)
```json
{
  "resourceLogs": [{
    "resource": {
      "attributes": [
        {"key": "service.name", "value": {"stringValue": "my-app"}}
      ]
    },
    "scopeLogs": [{
      "logRecords": [{
        "timeUnixNano": "1700000000000000000",
        "severityNumber": 9,
        "body": {"stringValue": "User logged in"},
        "attributes": [...],
        "traceId": "...",
        "spanId": "..."
      }]
    }]
  }]
}
```

### Output (Pipelines Record)
```json
{
  "timestamp": "2023-11-14T22:13:20.000Z",
  "timestamp_ns": 1700000000000000000,
  "severity_number": 9,
  "severity_text": "INFO",
  "body": "User logged in",
  "trace_id": "...",
  "span_id": "...",
  "attributes": {...},
  "resource_attributes": {"service.name": "my-app"},
  "scope_name": "...",
  "scope_version": "..."
}
```

## ğŸ”‘ Key Implementation Details

### Gzip Decompression
Uses Workers' native `DecompressionStream` API - no external dependencies needed.

### RPC vs HTTP
- **RPC**: Used by Cloudflare's native OTLP integration (configured in dashboard)
- **HTTP**: Used by external OTLP clients (standard /v1/logs endpoint)

### Schema Design
- **Stream Schema**: Stores nanosecond timestamps + all metadata
- **Sink Schema** (optional): Converts to microsecond timestamps for easier querying

### Error Handling
- Graceful handling of malformed requests
- Proper OTLP error responses
- Detailed error logging for debugging

## ğŸ“ˆ Performance

- **Batching**: Sends all records in one `pipeline.send()` call
- **Streaming**: Uses streaming decompression for large payloads
- **Memory**: Minimal memory footprint (no buffering)

## ğŸ§ª Testing Strategy

1. **Unit Testing**: Transform logic (manually tested with example data)
2. **Integration Testing**: Full end-to-end with real OTLP sources
3. **Load Testing**: Tested with compressed batches up to 3KB

## ğŸ”’ Security

- No credentials stored in code
- Pipeline binding handles auth automatically
- Input validation on all requests
- No eval() or unsafe operations

## ğŸ“ Documentation Coverage

- âœ… README with quick start
- âœ… Architecture diagrams
- âœ… API documentation
- âœ… Schema documentation
- âœ… Troubleshooting guide
- âœ… Contributing guidelines
- âœ… Example requests

## ğŸ“ Learning Resources

Users of this project will learn:
- How OTLP works
- Cloudflare Workers architecture
- Cloudflare Pipelines usage
- OpenTelemetry concepts
- TypeScript best practices

## ğŸ”® Future Enhancements

Potential additions (PRs welcome!):
- [ ] Support for OTLP traces (not just logs)
- [ ] Support for OTLP metrics
- [ ] Custom attribute filtering
- [ ] Sampling/rate limiting
- [ ] Multiple pipeline destinations
- [ ] Metrics dashboard

## ğŸ“ Support Channels

- GitHub Issues: Bug reports & features
- GitHub Discussions: Questions & ideas
- Documentation: Comprehensive guides

## âœ… Pre-Release Checklist

- [x] Code cleaned up
- [x] Debug logs removed
- [x] Documentation complete
- [x] Examples provided
- [x] License added
- [x] Contributing guide added
- [x] GitHub templates added
- [x] .gitignore updated
- [x] package.json complete
- [x] wrangler.toml sanitized
- [x] Unnecessary files removed

## ğŸš¢ Ready to Ship!

This project is now ready to:
1. Push to GitHub
2. Share with the community
3. Accept contributions
4. Help others build on Cloudflare

---

**Built with â¤ï¸ for the Cloudflare community**
